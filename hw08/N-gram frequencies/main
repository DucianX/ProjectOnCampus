from textcleaner import TextCleaner
from ngramfrequencies import NgramFrequencies


def main():
    # Load your text here
    with open('corpse_bride.txt', 'r', encoding='utf-8') as file:
        text = file.read()

    # Initialize TextCleaner and preprocess text
    cleaner = TextCleaner()
    tokenized_sentences = cleaner.process(text)

    # Initialize NgramFrequencies instances
    unigrams = NgramFrequencies(1)
    bigrams = NgramFrequencies(2)
    trigrams = NgramFrequencies(3)

    # Fill in the ngram frequencies
    # which is a list of sentences contains of words of a sentence
    for sentence in tokenized_sentences:
        for i in range(len(sentence)):
            unigrams.add_item(tuple(sentence[i:i+1]))  # Unigrams
            if i < len(sentence) - 1:
                bigrams.add_item(tuple(sentence[i:i+2]))  # Bigrams
            if i < len(sentence) - 2:
                trigrams.add_item(tuple(sentence[i:i+3]))  # Trigrams

    # Print top 10 n-grams
    print("Top 10 unigrams:", unigrams.top_n_freqs(10))
    print("Top 10 bigrams:", bigrams.top_n_freqs(10))
    print("Top 10 trigrams:", trigrams.top_n_freqs(10))


if __name__ == "__main__":
    main()
